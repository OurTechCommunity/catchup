Date: 15-04-2023

Duration: 3 hrs 43 mins

==== Topics Discussed

* link:https://twitter.com/rishit_dagli[Rishit Dagli^] and link:https://twitter.com/harshgkapadia[Harsh Kapadia^] talked about Artificial Intelligence (AI).
	**  Rishit talked about how link:https://openai.com/blog/chatgpt[ChatGPT^], link:https://platform.openai.com/docs/models/gpt-3-5[GPT-3.5^] and link:https://openai.com/product/gpt-4[GPT-4^] are Engineering marvels rather than research marvels. They keep adding more data and parameter-handling capabilities to the models.
	** Harsh brought up link:https://www.youtube.com/watch?v=FJACTC9wFhU[AWS CodeWhisperer and other AWS AI announcements^] and Rishit said that these new products are all battles of 'Who has more data and compute?' rather than pure AI innovations.
	** Harsh brought up link:https://en.wikipedia.org/wiki/Artificial_general_intelligence[Artificial General Intelligence (AGI)^] and Rishit said that a lot of very reputed professors are claiming that AGI is nowhere near and might not be discovered through these link:https://en.wikipedia.org/wiki/Large_language_model[Large Language Models (LLMs)^] that people claim are going to lead to AGI.
	** Harsh talked about how one of his professors, link:https://kaptchuk.com[Dr. Gabriel Kaptchuk^] is using LLMs in his link:https://en.wikipedia.org/wiki/Steganography[Steganography^] research project link:https://meteorfrom.space[Meteor^] to hide text in text.
	** Rishit talked about how he is learning a lot from working with his professors link:https://jimmylba.github.io[Dr. Jimmy Ba^] and link:https://www.cs.toronto.edu/~hinton[Dr. Geoffrey Hinton^], who have both done immense work in AI.
	** Rishit shared his research paper link:https://arxiv.org/abs/2304.05350[Astroformer: More Data Might Not be All You Need for Classification^] that got published! ðŸŽ‰
	** Rishit also shared his link:https://www.cs.toronto.edu/~rishit[personal page on the University of Toronto web site^].
	** Rishit told us how all ML models fundamentally use gradients to try to get closer to the correct answer from the answer it generated, and how doing away with gradients would presumably make models more efficient and easier to train.
	** Rishit added that there is loads of amazing research going on in AI that is currently not in the limelight.
* link:https://twitter.com/ambitions2003[Siddharth Kaduskar^] gave us an update on his project and told us how he has a clearer picture of what to do to build his OCR project after looking up multiple avenues.
* Anil Harwani told us about some of the internals of Linux.
	** link:https://stackoverflow.com/a/1311432/11958552[User space vs Kernel space^]
	** How does a Kernel figure out that a single core processor is in a infinite loop? There is an OS timer tick (link:https://en.wikipedia.org/wiki/Advanced_Programmable_Interrupt_Controller[APIC timer^]) that the processor uses to generate a regular interrupt and that is where it can be figured through usage monitoring that something is in an infinite loop.
	** What is there is a bug in the Operating System's link:https://en.wikipedia.org/wiki/Scheduling_(computing)[Scheduler^] or if the hardware is hung? The machine has to be reset, but before a cold reset, a hardware interrupt called the link:https://en.wikipedia.org/wiki/Non-maskable_interrupt[Non-maskable interrupt (NMI)^] is initiated through the hardware's control plane (that is usually not hung), that no software can trump. NMI is useful because it logs information before carrying out its resetting tasks, which aids in debugging the problem, which a cold reset would've made extremely difficult.
	** Gospels for Kernel level code
		*** A `while(1)` loop without `sleep()` somewhere inside it is usually a very bad idea, as it can be a source of resource hogging and performance bottlenecks.
		*** Polling for data should usually be between 15 to 20 ms and in rare cases, the fastest should usually be 1 ms.
	** Linux's link:https://man7.org/linux/man-pages/man2/bind.2.html[`bind()`^] that binds (assigns) a name (address) to a socket.
	** link:https://www.man7.org/linux/man-pages/man1/nice.1.html[The `nice` command^] that runs a program with modified scheduling priority.
	** link:https://unix.stackexchange.com/questions/153585/how-does-the-oom-killer-decide-which-process-to-kill-first[How does the Linux Out-of-Memory (OOM) Killer decide which process to kill first?^] (There is no right answer because there is a loss, but the OOM Killer has to be 'fair enough'.)
* We talked about the link:https://www.youtube.com/watch?v=b717Re0yaJ4[Rust Foundation's Trademark Policy Draft^] that has been causing uproar in the community.
	** We're wondering whether it is okay to mention that programming language's name in the point above after the stringent (and weird?) trademark policy draft.
	** Along similar lines, another restrictive licensing issue is link:https://twitter.com/hnasr/status/1646577859992104960[the DeWitt Clause^] that came up with Oracle's database. (Why're we not surprised that it's Oracle?)
		*** link:https://www.brentozar.com/archive/2018/05/the-dewitt-clause-why-you-rarely-see-database-benchmarks[The DeWitt Clause: Why You Rarely See Database Benchmarks^]
* link:https://twitter.com/WilfredAlmeida_[Wilfred Almeida^] talked about how he was struggling to deploy his link:https://rocket.rs[Rocket^] URL Shortener on link:https://railway.app[Railway^].
	** link:https://rocket.rs[Rocket^] is a web framework for 'the programming language with a stringent trademark policy we mentioned above'.
* link:https://twitter.com/furtado_jaden[Jaden Furtado^] gave a presentation on link:https://docs.google.com/presentation/d/1fLTBuUXlhOJi1RfHY87g36uAitfaDX-A_cgWaAJFLzQ/edit?usp=sharing&authuser=1[Mass Scanning Google Play-Store apps (On a Budget)^] that he gave at link:https://twitter.com/GdscWowMumbai[GDSC WOW Mumbai^] in April 2023.
